{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991ab2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_dir is added to sys.path\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# depending on the user's setup\n",
    "# we will try to find the superlinked_app directory\n",
    "# and add it to the sys.path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"superlinked-recipes\":\n",
    "    project_dir = cwd / \"projects\" / \"recipe-search\"\n",
    "elif cwd.name == \"notebooks\":\n",
    "    project_dir = cwd.parent\n",
    "else:\n",
    "    project_dir = cwd\n",
    "\n",
    "superlinked_app_dir = project_dir / \"superlinked_app\"\n",
    "assert superlinked_app_dir.exists(), (\n",
    "    f\"{superlinked_app_dir} does not exist\\n\"\n",
    "    \"are you sure you are in the recipe-search/notebooks directory?\"\n",
    ")\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.append(str(project_dir))\n",
    "    print(\"project_dir is added to sys.path\")\n",
    "else:\n",
    "    print(\"project_dir is already in sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648e2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biso/development/my_projects/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:17:20 httpx INFO   HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from superlinked_app.config import settings\n",
    "from superlinked import framework as sl\n",
    "import openai as openAILib\n",
    "\n",
    "\n",
    "# Create your OpenAI client as before\n",
    "openai_client = OpenAI(\n",
    "    base_url=settings.open_ai_base_url,\n",
    "    api_key=settings.openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "\n",
    "# Patch the OpenAI client with Instructor to enable structured output support\n",
    "client = instructor.from_openai(openai_client)\n",
    "\n",
    "# Define a Pydantic model for the expected structured response\n",
    "class InstructorResponse(BaseModel):\n",
    "    # Define fields you expect, for example:\n",
    "    # name: str\n",
    "    # age: int\n",
    "    # Customize this model based on your use case\n",
    "    pass\n",
    "\n",
    "# Example usage: send a request using the instructor model/configuration\n",
    "response = client.chat.completions.create(\n",
    "    model=settings.openai_model,  # e.g., \"instructor\" or \"gpt-3.5-turbo\"\n",
    "    response_model=InstructorResponse,  # your Pydantic model here\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Your prompt here\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Access structured data from response, e.g.:\n",
    "# print(response.name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.openai_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
